
rm(list = ls())

library(dplyr)
library(readxl)
library(ThesiStats)
library(PsyMetricTools)
library(openxlsx)
library(psych)
library(corrplot)
library(purrr)
library(broom)
library(corpcor)
library(huge)
library(bootnet)


######################################
# 1. Importamos la base de datos
#####################################
df <- readxl::read_excel("df_final.xlsx") 


df_new <- df %>%
  filter(Num_hijo > 0, Edad <= 50)

df %>%
  summarise(mayores_45 = sum(Edad > 45, na.rm = TRUE))
df %>%
  summarise(mayores_50 = sum(Edad > 50, na.rm = TRUE))
#glimpse(df)

#Invertir items
 items <- c("IPAQ1", "IPAQ10", "IPAQ16")
 df_new <- invertir_items(df, items, num_respuestas = 6, comienza_con_cero = FALSE)
# 
# items <- paste0("IPAQ", 1:25) 
# df_items <- df %>% select(all_of(items))
# 
# cor_mat <- cor(df_items, use = "pairwise.complete.obs")
# round(cor_mat[ c("IPAQ1", "IPAQ10", "IPAQ16"), ], 2)
# library(corrplot)
# corrplot(cor_mat, method = "color", tl.cex = 0.6)


######################################
# 2. Descriptivos de participantes
#####################################
library(dplyr)

tabla_participantes <- function(data,
                       continuas = c("Edad","Horas_semana"),
                       categoricas = c("Sexo","Nivel_educativo","Tipo_familia",
                                       "Prob_medicos","Trabajo","Economia","Ayuda",
                                       "Num_hijo","Num_hijas","Num_hijos"),
                                         digits = 2,
                                         mostrar_minmax = FALSE,
                                         ordenar_categorias_por_n = TRUE) {
  
  out <- tibble::tibble(`Variables sociodemográficas` = character(),
                        n = character(),
                        `%` = character())
  
  # Continuas
  for (v in continuas) {
    if (!v %in% names(data)) next
    x  <- suppressWarnings(as.numeric(data[[v]]))
    m  <- round(mean(x, na.rm=TRUE), digits)
    sd <- round(sd(x,   na.rm=TRUE), digits)
    if (mostrar_minmax) {
      mn <- round(min(x, na.rm=TRUE), digits)
      mx <- round(max(x, na.rm=TRUE), digits)
      val <- sprintf("%s (M, DE): %.*f (%.*f), %.*f–%.*f", v, digits, m, digits, sd, digits, mn, digits, mx)
    } else {
      val <- sprintf("%s (M, DE): %.*f (%.*f)", v, digits, m, digits, sd)
    }
    out <- dplyr::bind_rows(out, tibble::tibble(`Variables sociodemográficas` = val, n = "", `%` = ""))
  }
  
  # Categóricas
  for (v in categoricas) {
    if (!v %in% names(data)) next
    out <- dplyr::bind_rows(out, tibble::tibble(`Variables sociodemográficas` = v, n = "", `%` = ""))
    
    tab <- data %>%
      dplyr::count(.data[[v]], name = "n") %>%
      dplyr::mutate(`%` = round(100 * n / sum(n), digits),
                    cat = as.character(.data[[v]])) %>%
      dplyr::select(cat, n, `%`)
    
    if (ordenar_categorias_por_n) tab <- dplyr::arrange(tab, dplyr::desc(n))
    
    tab <- tab %>%
      dplyr::transmute(`Variables sociodemográficas` = paste0("  - ", cat),
                       n = as.character(n),
                       `%` = sprintf(paste0("%.", digits, "f"), `%`))
    
    out <- dplyr::bind_rows(out, tab)
  }
  
  out
}

# Uso:
tabla <- tabla_participantes(df_new)

#Descargar
openxlsx::write.xlsx(list(Participantes = tabla),
                     "Output/tabla_participantes.xlsx", overwrite = TRUE)


####################################
# 3. Hacer sumatoria
###################################

texto <- readLines("Texto.txt", encoding = "UTF-8")
code <- ThesiStats::generate_code(texto, "df")
cat(code)

# df_new <- df_new %>% 
#   rowwise() %>% 
#   mutate(Burnout = sum(c_across(c(PBA1,PBA2,PBA3,PBA4,PBA5,PBA6,PBA7,PBA8,PBA9,PBA10,PBA11,PBA12,PBA13,PBA14,PBA15,PBA16,PBA17,PBA18,PBA19,PBA20,PBA21,PBA22,PBA23))),
#          Essentialism = sum(c_across(c(IPAQ1,IPAQ2, IPAQ4,IPAQ6,IPAQ12,IPAQ16,IPAQ17,IPAQ20))),
#          Stimulation = sum(c_across(c(IPAQ7,IPAQ10, IPAQ14,IPAQ18))),
#          Challenge = sum(c_across(c(IPAQ3,IPAQ9, IPAQ21,IPAQ25))),
#          Fulfilment = sum(c_across(c(IPAQ5,IPAQ8, IPAQ13,IPAQ15,IPAQ22,IPAQ23))),
#          Childcenter = sum(c_across(c(IPAQ11,IPAQ19, IPAQ24))),
#          Depression = sum(c_across(c(PHQ1,PHQ2,PHQ3,PHQ4,PHQ5,PHQ6,PHQ7,PHQ8,PHQ9))),
#          Life_satisfaction = sum(c_across(c(SATI1,SATI2,SATI3)))) %>% 
#   ungroup()

df_new <- df_new %>% 
  rowwise() %>% 
  mutate(Burnout_1 = sum(c_across(c(PBA1,PBA3,PBA4,PBA7,PBA8,PBA10,PBA12,PBA2))),
         Burnout_2 = sum(c_across(c(PBA20,PBA17,PBA18,PBA19,PBA11,PBA22,PBA16,PBA23))),
         Essentialism = sum(c_across(c(IPAQ1,IPAQ2, IPAQ4,IPAQ6,IPAQ12,IPAQ16,IPAQ17,IPAQ20))),
         Stimulation = sum(c_across(c(IPAQ7,IPAQ10, IPAQ14,IPAQ18))),
         Challenge = sum(c_across(c(IPAQ3,IPAQ9, IPAQ21,IPAQ25))),
         Fulfilment = sum(c_across(c(IPAQ5,IPAQ8, IPAQ13,IPAQ15,IPAQ22,IPAQ23))),
         Childcenter = sum(c_across(c(IPAQ11,IPAQ19, IPAQ24))),
         Depression = sum(c_across(c(PHQ1,PHQ2,PHQ3,PHQ4,PHQ5,PHQ6,PHQ7,PHQ8,PHQ9))),
         Life_satisfaction = sum(c_across(c(SATI1,SATI2,SATI3)))) %>% 
  ungroup()


df_variables <- df_new %>%
  select(Burnout_1, Burnout_2,
         Essentialism,
         Stimulation, Challenge, Fulfilment, Childcenter, 
         Depression, Life_satisfaction)


# descriptivos <- psych::describe(df_variables)
# print(descriptivos)

# Descriptivos
library(ThesiStats)
texto2 <- readLines("Texto_nuevo.txt", encoding = "UTF-8")

result1 <- calculate_descriptives(df_new, "Burnout_1", "Life_satisfaction")
result1

# Fiabilidad
## 1) Unidimensional (ítems -> F1)
omega_lav1f <- function(dat, items, estimator = "WLSMV") {
  mod <- paste("F1 =~", paste(items, collapse = " + "))
  fit <- lavaan::cfa(mod, data = dat, estimator = estimator,
                     ordered = items, std.lv = TRUE)
  as.numeric(semTools::reliability(fit, what = "omega"))
}

# 2) General (múltiples factores): devuelve vector nombrado con omegas
omega_lav <- function(dat, model, ordered_items, estimator = "WLSMV") {
  fit <- lavaan::cfa(model, data = dat, estimator = estimator,
                     ordered = ordered_items, std.lv = TRUE)
  semTools::reliability(fit, what = "omega")  # vector con nombres de factores
}

mod_ipaq <- '
Essentialism =~ IPAQ1 + IPAQ2 + IPAQ4 + IPAQ6 + IPAQ12 + IPAQ16 + IPAQ17 + IPAQ20
Fulfilment   =~ IPAQ7 + IPAQ10 + IPAQ14 + IPAQ18
Stimulation  =~ IPAQ3 + IPAQ9 + IPAQ21 + IPAQ25
Challenge    =~ IPAQ5 + IPAQ8 + IPAQ13 + IPAQ15 + IPAQ22 + IPAQ23
Childcenter  =~ IPAQ11 + IPAQ19 + IPAQ24
'
mod_pba <- '
Burnout_1 =~ PBA1 + PBA3 + PBA4 + PBA7 + PBA8 + PBA10 + PBA12 + PBA2
Burnout_2 =~ PBA20 + PBA17 + PBA18 + PBA19 + PBA11 + PBA22 + PBA16 + PBA23
'



## Result
omega_burnout <- omega_lav(df, mod_pba, ordered_items = paste0("PBA", 1:23))
omega_creencias <- omega_lav(df, mod_ipaq, ordered_items = paste0("IPAQ", 1:25))
omega_depresion <- omega_lav1f(df_new, paste0("PHQ", 1:9))
omega_satisfaccion <- omega_lav1f(df_new, paste0("SATI", 1:3))

tabla_omega <- tibble::tibble(
  Variables = c("Burnout_1", "Burnout_2", "Essentialism", "Stimulation", "Challenge",
                "Fulfilment", "Childcenter", "Depression", "Life_satisfaction"),
  Omega = round(c(omega_burnout, omega_creencias, omega_depresion, omega_satisfaccion), 2)
)

# Ver tabla
print(tabla_omega)

Tabla1 <- inner_join(result1, tabla_omega, by = "Variables")
Tabla1


#Guardar tabla
openxlsx::write.xlsx(Tabla1, file = "Output/Tabla_descriptive.xlsx", overwrite = T)



######################################
# 4. Normalidad
#####################################

## Identificar outlier
mahal_dist <- mahalanobis(df_variables, 
                          center = colMeans(df_variables, na.rm = TRUE), 
                          cov = cov(df_variables, use = "pairwise.complete.obs"))
p <- ncol(df_variables)
n <- nrow(df_variables)
alpha <- 0.001
cutoff <- qchisq(1 - alpha, df = p)

outliers <- which(mahal_dist > cutoff)
length(outliers)  # cuántos
outliers           # qué filas

df_variables <- df_variables[-outliers, ]

#Univariado
library(MVN)
mvn(df_variables, mvnTest = "mardia", cov = T, multivariatePlot = "qq")

# Multivariado
mardia_test(df_variables)
Normalidad <- Multivariate_plot(df_variables, 
                                xmin = 20, 
                                xmax = 23, 
                                ymin = 4, 
                                ymax = 8)
print(Normalidad)

# Guardar como imagen
ggsave("Output/Figura_Normalidad_multivariad.jpg", plot = Normalidad, 
       width = 8, height = 6, dpi = 800)

######################################
# 4. Transformación
#####################################

# transformar datos no parametricos en parametricos
library(huge)
data_npn <- huge.npn(df_variables, npn.func = "shrinkage", 
                     npn.thresh = NULL, verbose = TRUE)
df_transformed <- as.data.frame(apply(data_npn, 2, 
                                      function(x) as.numeric(round(x, digits = 2))))


######################################
# 4. Correlación
#####################################

# Calcular la matriz de correlaciones
M <- cor(df_transformed)
cor <- corrplot(M, method = "circle", 
         type = "full",
         tl.col = "black", 
         tl.srt = 35, 
         number.cex = 0.55,
         addCoef.col = "black") 

# Guardar como imagen
jpeg("Output/Figura_correlación 3.jpg", width = 8, height = 6, units = "in", res = 800)
corrplot(M, method = "circle", 
         type = "full",
         tl.col = "black", 
         tl.srt = 35, 
         number.cex = 0.55,
         addCoef.col = "black")
dev.off()

# Verificar si la matriz es definida positiva
library(corpcor)
is.positive.definite(M) # TRUE

######################################
# 5. Redundancia
#####################################

gb <- networktools::goldbricker(df_transformed, p = 0.05, 
                                method = "hittner2003", threshold=0.25, #method "williams1959"
                                corMin=.50, progressbar = TRUE)
gb


######################################
# 5. Preparar comunidades
#####################################

names <- c("Burnout",  "Intensive Attitudes", "Depression", "Satisfaction")
values <- c(2,5,1, 1)
groups <- InterconectaR::structure_groups(names, values)
groups


######################################
# 6. Estimar la red
#####################################
network <-
  bootnet::estimateNetwork(df_transformed,
                           default = 'ggmModSelect',
                           stepwise = TRUE,
                           corMethod = "spearman",
                           criterion = "ebic")

# Estimar el R2
library(mgm)
library(InterconectaR)
type <- c(rep("g", 9))
level <- c(rep(1, 9))

#Estimar los R2
error_Model <- mgm_error_metrics(data = df_transformed,
                                 type = type,
                                 level = level)

#Extraer solo los valores de interes
error_Model <- error_Model$errorCon$R2
error_Model

## Plot
# mis_colores <- c("#F5B7B1", "#AED6F1", "#FDBF6F")  #"#A6CEE3", "#B2DF8A", "#FDBF6F" "#F5B7B1"
# mis_colores <- c("#A3E4D7",  # verde agua
#                  "#F9E79F",  # crema
#                  "#F1948A")  # coral suave
# mis_colores <- c("#F5CBA7",  # melocotón claro
#                  "#D2B4DE",  # lavanda
#                  "#AED6F1")  # celeste claro
mis_colores <- c("#FAD7A0",  # amarillo arena
                 "#F1948A",  # coral claro
                 "#A3E4D7",
                 "#85C1E9")  # gris azulado suave
# mis_colores <- c("#C39BD3",  # violeta suave
#                  "#F8C471",  # mostaza pastel
#                  "#85C1E9")  # azul cielo

#colnames(network$graph)
labels_nuevos <- c("Burn1", "Burn2" , "Esse", "Stim", "Chall", "Fulf", "Chil", "Depr", "Sati")

g1 <- qgraph::qgraph(network$graph,
                     groups = groups, 
                     labels = labels_nuevos,
                     color = mis_colores,
                     curveAll = 2,
                     vsize = 7.5,
                     esize = 3,
                     #palette = "colorblind",
                     layout = "spring", # Fruchterman-Reingold
                     edge.labels = T,
                     pie = error_Model,
                     layoutScale =c(0.8,0.8),
                     legend.cex = 0.6,
                     label.cex = 0.9,
                     edge.label.cex = 0.6)

## Guardar imagen
jpeg("Output/red_qgraph 3.jpg", width = 8.5, height = 6.5, units='in', res = 300)

g1 <- qgraph::qgraph(network$graph,
                     groups = groups, 
                     labels = labels_nuevos,
                     color = mis_colores,
                     curveAll = 1.2,
                     vsize = 7.5,
                     esize = 4,
                     #palette = "colorblind",
                     layout = "spring", # Fruchterman-Reingold #groups #spring
                     edge.labels = T, 
                     pie = error_Model,
                     layoutScale =c(0.9,0.9),
                     legend.cex = 0.5,
                     label.cex = 0.9,
                     edge.label.cex = 0.7)

dev.off()

######################################
# 6. Estimar la centralidad
#####################################

expect_ <- qgraph::centralityPlot(network, include = "ExpectedInfluence", scale = "z-scores", 
                                  orderBy = "ExpectedInfluence") + 
                                  theme(axis.text.y = element_text(size = 20), 
                                        axis.text.x = element_text(size = 25), legend.text = element_text(size = 20), 
                                        legend.title = element_text(size = 20), axis.title.y = element_text(size = 20), 
                                        axis.title.x = element_text(size = 25),
                                        strip.text = element_text(size = 20))

expect_

ggplot2::ggsave("Output/Figura 2 - derecha.jpg",
                plot = expect_,
                width = 9.5, height = 6.5, dpi = 800)


######################################
# 6. Estimar la centralidad 2
#####################################
library(qgraph)
library(dplyr)
library(networktools)
library(tibble)

# Cálculo de la tabla de centralidad de influencia esperada
cents_expect <- qgraph::centralityTable(network) %>%
  filter(measure == "ExpectedInfluence")

# Cálculo de la influencia de puente usando la función bridge
b <- bridge(g1, communities = groups, useCommunities = "all", normalize = FALSE)

# Conversión del resultado en un data frame y adición de nombres de filas
cents <- as.data.frame(cbind(b$`Bridge Expected Influence (1-step)`)) %>%
  rownames_to_column(var = "Item") %>%
  mutate(measure1 = "Bridge Expected Influence") %>% mutate(V1 = scale(V1))

# Unión de las tablas de centralidad y selección/renombrado de columnas
cents2 <- bind_cols(cents, cents_expect) %>%
  select(node, Item, V1, value) %>%
  rename(value_BEI = V1, value_EI = value)
cents2 %>% arrange(desc(value_EI))

# Importar las librerías necesarias
library(ggplot2)
library(dplyr)
library(tidyr)
cents2 %>% arrange(value_EI)
# Preparar los datos para el gráfico combinado
cents_long <- cents2 %>%
  pivot_longer(cols = c("value_BEI", "value_EI"), names_to = "Measure", values_to = "Value") %>%
  mutate(Measure = recode(Measure, 
                          "value_BEI" = "Bridge Expected Influence", 
                          "value_EI" = "Expected Influence")) %>% rename(Centrality = Measure)

# Crear el gráfico combinado con dos líneas
Figura1_Derecha <- ggplot(cents_long, aes(x = Value, y = reorder(Item, Value), color = Centrality, group = Centrality)) +
  geom_point() +
  geom_line() +
  theme_minimal() +
  labs(title = "",
       x = "Value",
       y = "Item") +
  scale_color_manual(values = c("Bridge Expected Influence" = "#FF0000", "Expected Influence" = "#00A08A")) +
  theme(axis.text.y = element_text(size = 10), 
        axis.text.x = element_text(size = 10),
        legend.text = element_text(size = 8), 
        legend.title = element_text(size = 8),
        legend.position = "bottom")
Figura1_Derecha

ggsave(filename = "Output/Centralidad 3.jpg", plot = Figura1_Derecha,
       height = 5, width = 10, dpi = 600, units = c("in"))

######################################
# 6. Combinar Plot
#####################################

# Función para combinar plot

combine_graphs_centrality2 <- function(
    Figura1_Derecha, network, groups, error_Model, labels = NULL,
    abbreviate_labels = FALSE, ncol = 2, widths = c(0.5, 0.6),
    dpi = 600, legend.cex = 0.1,
    color = NULL, vsize = 7.5,  
    esize = 3
){
  required_packages <- c("ggplot2","qgraph","png","grid","patchwork","Cairo")
  for (pkg in required_packages) {
    if (!require(pkg, character.only = TRUE, quietly = TRUE)) {
      install.packages(pkg, dependencies = TRUE); library(pkg, character.only = TRUE)
    }
  }
  abbreviate_names <- function(labels) substr(labels, 1, 3)
  final_labels <- if (is.null(labels)) network$labels else labels
  if (abbreviate_labels) final_labels <- abbreviate_names(final_labels)
  # --- Validación simple de colores ---
  if (!is.null(color)) {
    n_nodes <- length(final_labels)
    if (!(length(color) %in% c(n_nodes, length(groups)))) {
      stop("`color` debe tener longitud = nº de nodos (", n_nodes,
           ") o = nº de grupos (", length(groups), ").")
    }
  }
  tmp_file <- tempfile(fileext = ".png")
  Cairo::CairoPNG(tmp_file, width = 1600, height = 1000, res = dpi)
  qgraph::qgraph(
    network$graph, groups = groups,
    curveAll = 2, vsize = vsize, esize = esize,
    layout = "spring", edge.labels = TRUE,
    labels = final_labels, legend.cex = legend.cex, legend = TRUE,
    details = FALSE, node.width = 0.8, pie = error_Model,
    layoutScale = c(1.0, 1.0), GLratio = 2.5, edge.label.cex = 1.25,
    # >>> LÍNEAS CLAVE <<<
    color   = color,
    palette = if (is.null(color)) "pastel" else NULL
  )
  dev.off()
  img <- png::readPNG(tmp_file)
  g1_raster <- grid::rasterGrob(img, interpolate = TRUE)
  p1 <- ggplot2::ggplot() +
    ggplot2::annotation_custom(grob = g1_raster, xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
    ggplot2::theme_void()
  Figura1_Derecha_modificada <- Figura1_Derecha +
    ggplot2::labs(color = "Metric", shape = "Metric") +
    ggplot2::scale_color_discrete(labels = c("Bridge EI","EI")) +
    ggplot2::scale_shape_discrete(labels = c("Bridge EI","EI")) +
    ggplot2::theme(legend.direction = "horizontal", legend.position = "bottom", legend.box = "horizontal")
  combinado <- p1 + Figura1_Derecha_modificada + patchwork::plot_layout(ncol = ncol, widths = widths)
  class(combinado) <- c("silent_gg", class(combinado))
  assign("print.silent_gg", function(x, ...) suppressWarnings(NextMethod()), envir = .GlobalEnv)
  unlink(tmp_file)
  return(combinado)
}

#mis_colores <- c("#FAD7A0","#F1948A","#A3E4D7","#85C1E9")  # por grupo
#labels_nuevos <- c("Burn","Esse","Stim","Chall","Fulf","Chil","Depr","Sati")

plot_combinado <- combine_graphs_centrality2(
                  Figura1_Derecha = Figura1_Derecha, 
                  network = network, 
                  groups = groups, 
                  error_Model = error_Model, 
                  ncol = 2, 
                  widths = c(0.70, 0.40), 
                  dpi = 300,
                  legend.cex = 0.40,
                  labels = labels_nuevos,
                  color = mis_colores,
                  vsize = 14,
                  esize = 10
)

ggplot2::ggsave(
  filename = "Output/plot_combinado 3.jpg", 
  plot = plot_combinado,
  width = 10, height = 6, dpi = 600
)


######################################
# 7. Descripción de la red
#####################################

library(qgraph)
describe <- InterconectaR::get_edge_weights_summary(network)
describe

pesos <- getWmat(network)
pesos_vec <- pesos[upper.tri(pesos)]  # extraer solo parte superior
mean(abs(pesos_vec[pesos_vec != 0]))  # promedio absoluto excluyendo ceros

# Density
InterconectaR::Density_report(network$graph)

#Transitividad
library(igraph)
g <- graph_from_adjacency_matrix(getWmat(network), mode = "undirected", weighted = TRUE)
transitivity(g, type = "global")  # Transitivity: probabilidad de que dos nodos estén conectados con un tercer nodo (conexión entresí)


######################################
# 8. Estabilidad y precisión
#####################################

# 1. Bootstrap network estimation
library(bootnet)
caseDroppingBoot <- bootnet::bootnet(network, 
                                     boot = 1000, 
                                     type = "case", #Esto cambio
                                     nCores = 8,
                                     statistics = "all",
                                     communities=groups)

result_case <- InterconectaR::filter_correlation_stability(caseDroppingBoot)
result_case

plot1 <- plot(caseDroppingBoot, 
              statistics = c("ExpectedInfluence" ,"BridgeExpectedInfluence"),
              labels = labels)
print(plot1)

#Descargar
ggsave(
  filename = "Output/bootstrap 1.3.jpg",  
  plot     = plot1,
  width    = 8,   
  height   = 6,    
  dpi      = 800   
)

#cs <- corStability(caseDroppingBoot)
#print(cs)

# Combining Precision
nonParametricBoot <- bootnet::bootnet(network, 
                                      boot = 1000, 
                                      type = "nonparametric", #Esto cambio
                                      nCores = 8,
                                      statistics = "all",
                                      communities=groups)

#plot(nonParametricBoot, "edge", plot = "difference")

plot2 <- plot(nonParametricBoot, 
              labels = labels, 
              order = "sample", 
              statistics = "edge")
print(plot2)

#Descargar
ggsave(
  filename = "Output/bootstrap 2.3.jpg",  
  plot     = plot2,
  width    = 8,   
  height   = 6,    
  dpi      = 800   
)

# Combining Stability and Accuracy
combined_plot <- InterconectaR::plot_centrality_stability(caseDroppingBoot,
                                                          nonParametricBoot, 
                                                          statistics = c("ExpectedInfluence" ,
                                                                         "BridgeExpectedInfluence"), 
                                                          #height = 9, 
                                                          #width = 13, 
                                                          #dpi = 600,
                                                          labels = T)

ggplot2::ggsave(
  filename = "Output/Bootstrap.3.jpg", 
  plot = combined_plot,
  width = 10, height = 6, dpi = 600
)

######################################
# 9. Matrices
#####################################


##Correlaciones de matrices
# Get a summary of the network's edge weights
edge_summary <- get_edge_weights_summary(network)
edge_summary

centrality_results <- InterconectaR::centrality_plots2(
  qgraph_obj = g1,
  network = network,
  measure0 = "ExpectedInfluence",
  measure1 = "Bridge Expected Influence (1-step)",
  legend_labels = c("EI", "BEI"),
  groups        = groups
)
centrality_results


# Calculate differential variability of the GGM
result_cor_sd <- calculate_centrality_sd_correlation(df_variables, centrality_results)
result_cor_sd



######################################
# 10. Comaparar por sexo
#####################################


### Comparar por sexo
#Redes_Sexo %>% count(Sexo)
# length(Redes_Sexo$Estimacion)
df_new %>% count(Sexo)

# df_comp <- df_new %>% 
#   select(Sexo, Autoeficacia:Postergación)
# 
# balanced_data <- PsyMetricTools::smote_multiclass(df_comp, outcome = "Sexo", perc_maj = 100, k = 5)
# balanced_data %>% count(Sexo)


Redes_Sexo = df_new %>%
  select(Sexo, Burnout_1, Burnout_2, Essentialism, Stimulation, Challenge, Fulfilment,
         Childcenter, Depression, Life_satisfaction) %>% 
  group_nest(Sexo) %>%
  mutate(
    #data = map(data,
    #          ~ select(., tidyselect:::where(~ !all(is.na(.))))),
    Estimacion = map(data, ~ mgm(as.matrix(.x), 
                                 type = c(rep("g", 9)), 
                                 level = c(rep(1,9)),
                                 k = 2)))

error <- lapply(1:2, function(i) {
  pred <- predict(object = Redes_Sexo$Estimacion[[i]], 
                  data = Redes_Sexo$data[[i]], 
                  errorCon = c("RMSE", "R2"))
  error <- pred$errors %>% as_tibble() %>% select(Variable, R2) %>% pull()
  return(error)
})

error[[1]]
error[[2]]


## Estimar
#generation of a specific data
Femenino= df_new %>%
  filter(Sexo == "madre") %>%
  select(Burnout_1, Burnout_2, Essentialism, Stimulation, Challenge, Fulfilment,
         Childcenter, Depression, Life_satisfaction) %>%
  na.omit() %>%
  as.data.frame()

Masculino = df_new %>%
  filter(Sexo == "padre") %>%
  select(Burnout_1, Burnout_2, Essentialism, Stimulation, Challenge, Fulfilment,
         Childcenter, Depression, Life_satisfaction) %>%
  na.omit() %>%
  as.data.frame()

#Estimation of the subgroups (yes and no)
network_Female <- estimateNetwork(Femenino,
                                  default = 'ggmModSelect',
                                  stepwise = TRUE,
                                  corMethod = "spearman",
                                  tuning = 0
)

network_Male <- estimateNetwork(Masculino,
                                default = 'ggmModSelect',
                                stepwise = TRUE,
                                corMethod = "spearman",
                                tuning = 0
)
L <- averageLayout(network_Female,network_Male)
L




## Plot de redes según sexo
jpeg("./Output/Figura comparación de red.3.jpg", 
     width=8.5, height=8.5, 
     units='in',res=800)
layout(t(1:2))

#especificar prediseño
# mis_colores <- c("#FAD7A0",  # amarillo arena
#                  "#F1948A",  # coral claro
#                  "#A3E4D7")  # gris azulado suave
#colnames(network$graph)


g3 <- qgraph(network_Female$graph, 
             layout = L,
             vsize = 8, #tama?o de los nodos
             esize = 6,
             color = mis_colores,
             labels = labels_nuevos,
             groups = groups,
             legend = F, #Cambien aqu?
             edge.labels = T,
             edge.label.cex = 1,
             curveAll = 2,
             curve = 0.55,
             pie = error[[1]],
             cut = 0.00,
             title = "Madres")


g4 <- qgraph(network_Male$graph, 
             layout = L,
             vsize = 8, #tama?o de los nodos
             esize = 6,
             groups = groups,
             color = mis_colores,
             labels = labels_nuevos,
             legend = F,
             edge.labels = T, #Cambien aqu?
             edge.label.cex = 1,
             cut = 0.00,
             curveAll = 2,
             curve = 0.55,
             pie = error[[2]],
             title = "Padres")

dev.off()



InterconectaR::Density_report(network_Female$graph)
InterconectaR::Density_report(network_Male$graph)



######################################
# 11. Comparison usando NCT
#####################################

set.seed(2025) 
library(NetworkComparisonTest)
res <-NCT(network_Female, network_Male, 
          binary.data=F,
          test.edges=TRUE, 
          edges="all", 
          it = 500, 
          test.centrality = TRUE,
          verbose = FALSE)

res

#NETWORK INVARIANCE TEST 
res$nwinv.real # Test statistic M:  
res$nwinv.pval #p-value 

#GLOBAL STRENGTH INVARIANCE TEST 
res$glstrinv.real #Test statistic S
res$glstrinv.pval #p-value



######################################
# 12. Centralidad por Sexo
#####################################
library(networktools)
## brigdge expected influence
c <- bridge(g3, communities= groups, useCommunities = "all", normalize = F)
d <- bridge(g4, communities= groups, useCommunities = "all", normalize = F)

cents_cd <- as.data.frame(cbind(c$`Bridge Expected Influence (1-step)`,
                                d$`Bridge Expected Influence (1-step)`))

#cents_cd <- as.data.frame(cbind(c$`Bridge Strength`,
#                              d$`Bridge Strength`))

cents_cd <- as.data.frame(cbind(
  Madres = c$`Bridge Expected Influence (1-step)`,
  Padres = d$`Bridge Expected Influence (1-step)`
)) %>%
  mutate(Variables = rownames(.)) %>%
  reshape2::melt(id.vars = "Variables", 
                 variable.name = "Group", 
                 value.name = "value") %>%
  group_by(Group) %>%
  mutate(zscore = as.numeric(scale(value))) %>%
  ungroup() %>%
  mutate(across(where(is.numeric), round, 2))
cents_cd
#Gráfico de puente ordenado
cents_cd$overall = "Bridge Expected Influence"
Figure3_Derecha <-
  ggplot(cents_cd, aes(x = forcats::fct_reorder(factor(Variables), zscore, mean), y = zscore, group=Group)) +
  geom_line(aes(linetype=Group, color=Group)) +
  geom_point(aes(shape = Group, color=Group), size = 2) +
  scale_shape_manual(values=c(15, 16)) +
  scale_colour_manual(values=c("red", "#0C99C6")) +
  xlab("Variables") + ylab("z-score")+
  theme_bw(base_size = 8) +
  theme(legend.position="top")+
  theme(axis.text.x = element_text(angle = 70, vjust = 0.5, hjust=0.5, size = 7)) +
  facet_wrap(~ overall, ncol = 1, strip.position = "top")
#+
#facet_wrap(~overall)
# coord_flip()
# theme(legend.position="none")

Figure3_Derecha

# ggsave(filename = "Output/Figure3 Derecha.jpg", plot = Figure3_Derecha,
#        height = 9.81, width = 12.55, dpi = 600, units = c("cm")) 


# Expected influence
library(reshape2)
library(forcats)
library(ggplot2)

# 2. Calcula Expected Influence one-step
ei3 <- expectedInf(g3, step = 1)
ei4 <- expectedInf(g4, step = 1)
ei3_step1 <- ei3$step1
ei4_step1 <- ei4$step1

# 3. Combina en data.frame largo
cents_ei <- as.data.frame(cbind(Madres = ei3_step1, Padres = ei4_step1)) %>%
  mutate(Variables = rownames(.)) %>%
  reshape2::melt(id = "Variables", variable.name = "Group", value.name = "value") %>%
  mutate(Group = factor(Group, levels = c("Madres", "Padres")),
         zscore = as.numeric(scale(value))) %>%
  mutate

# 4. Graficar
cents_ei$Metric <- "Expected Influence"
Figure_EI_PorSexo <- ggplot(cents_ei, aes(
  x = forcats::fct_reorder(factor(Variables), zscore, mean),
  y = zscore,
  group = Group
)) +
  geom_line(aes(linetype = Group, color = Group)) +
  geom_point(aes(shape = Group, color = Group), size = 2) +
  scale_shape_manual(values = c(16, 16)) +
  scale_colour_manual(values = c("Madres"="red", "Padres"="#0C99C6")) + 
  xlab("Variables") + ylab("z-score") +
  theme_bw(base_size = 8) +
  theme(legend.position = "top") +
  theme(axis.text.x = element_text(angle = 70, vjust = 0.5, hjust = 0.5, size = 7)) +
  facet_wrap(~ Metric, ncol = 1, strip.position = "top")

# ggsave(filename = "Output/Figure3B Derecha.jpg", plot = Figure_EI_PorSexo,
#        height = 9.81, width = 12.55, dpi = 600, units = "cm")

## Combinar plot
library(patchwork)
combined <- Figure_EI_PorSexo + Figure3_Derecha +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = "A") & 
  theme(plot.tag = element_text(face = "bold"))

print(combined)

ggsave(
  filename = "Output/Figure3_centralidad_sexo.3.jpg",
  plot = combined,
  height = 3, width = 6,
  dpi = 600, units = "in"
)



######################################
# 13. Matrix effect size
#####################################

#Calculation of effect size - Comparing adjacent matrices
network1_adjacency <- getWmat(network_Female)
network2_adjacency <- getWmat(network_Male)

cor(network1_adjacency[lower.tri(network1_adjacency)], network2_adjacency[lower.tri(network2_adjacency)], method = "spearman")

#Calculation of effect size from bootstrap
compare_matrices_bootstrap <- function(network1_adjacency, network2_adjacency, num_repetitions) {
  library(boot)
  
  spearman_correlation <- function(mat1, mat2, indices) {
    mat1_vec <- as.vector(mat1[indices])
    mat2_vec <- as.vector(mat2[indices])
    return(cor(mat1_vec, mat2_vec, method = "spearman"))
  }
  
  set.seed(2023)
  
  lower_tri_indices <- lower.tri(network1_adjacency)
  
  network1_adjacency_vec <- as.vector(network1_adjacency[lower_tri_indices])
  network2_adjacency_vec <- as.vector(network2_adjacency[lower_tri_indices])
  
  # Almacenar las correlaciones de Spearman
  spearman_correlations <- numeric(num_repetitions)
  
  boot_obj <- boot(data = cbind(network1_adjacency_vec, network2_adjacency_vec),
                   statistic = function(data, indices) {
                     spearman_correlation(network1_adjacency_vec, network2_adjacency_vec, indices)
                   },
                   R = num_repetitions)
  
  mean_correlation <- mean(boot_obj$t)
  
  similarity_status <- if (mean_correlation > 0.8) {
    "Las matrices son similares."
  } else if (mean_correlation < 0.2) {
    "Las matrices son diferentes."
  } else {
    "Las matrices tienen alguna similitud pero también tienen diferencias."
  }
  
  return(list(
    spearman_correlations = boot_obj$t,
    mean_correlation = mean_correlation,
    similarity_status = similarity_status
  ))
}

# Uso de la función
result <- compare_matrices_bootstrap(network1_adjacency, network2_adjacency, 1000)
spearman_correlations <- result$spearman_correlations
mean_correlation <- result$mean_correlation
result$similarity_status

result$spearman_correlations %>% psych::describe()


######################################
# 14. Tamaño de la muestra
#####################################

# Powerly
library(powerly)

set.seed(2025)
# Generate a `GGM` model.
true_model <- generate_model(
  type = "ggm",
  nodes = 8,
  density = .5
)

true_model

# Run the method.
results <- powerly(
  range_lower = 300,
  range_upper = 600,
  samples = 30,
  replications = 40,
  measure = "sen",
  statistic = "power",
  measure_value = .6,
  statistic_value = .9,
  model = "ggm",
  model_matrix = true_model,
  cores = 8,
  verbose = TRUE
)

# Plot method run.
plot(results)


# Run validation.
validation <- validate(
  method = results,
  replications = 1000,
  cores = 8
)

# Plot validation.
plot(validation)
validation$recommendation












